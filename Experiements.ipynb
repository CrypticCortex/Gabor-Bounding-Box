{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "reader = PdfReader('Sanskrit_Text (1).pdf')\n",
    "page = reader.pages[1]\n",
    "print(page.extract_text((0, 90)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image\n",
    "img = cv2.imread('/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg') \n",
    "\n",
    "# Create Gabor filter bank\n",
    "gabor_kernels = cv2.getGaborKernel((5, 5), 4.0, theta=0, lambd=10.0, gamma=0.5)\n",
    "\n",
    "# Filter image with Gabor filters\n",
    "gabor_imgs = []\n",
    "for kernel in gabor_kernels:\n",
    "    filtered_img = cv2.filter2D(img, -1, kernel)\n",
    "    gabor_imgs.append(filtered_img)\n",
    "\n",
    "# Detect edges\n",
    "edges = cv2.Canny(gabor_imgs[0], 50, 200) \n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, minLineLength=10, maxLineGap=5)\n",
    "\n",
    "# Draw bounding boxes on original image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.rectangle(img, (x1+15, y1), (x2+15, y2), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('output.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg') \n",
    "\n",
    "# Create Gabor filter bank\n",
    "gabor_kernels = cv2.getGaborKernel((5, 5), 4.0, theta=0, lambd=10.0, gamma=0.5)\n",
    "\n",
    "# Filter image with Gabor filters\n",
    "gabor_imgs = []\n",
    "for kernel in gabor_kernels:\n",
    "    filtered_img = cv2.filter2D(img, -1, kernel)\n",
    "    gabor_imgs.append(filtered_img)\n",
    "\n",
    "# Detect edges\n",
    "edges = cv2.Canny(gabor_imgs[0], 50, 200)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, minLineLength=10, maxLineGap=5)\n",
    "\n",
    "# Group lines based on y-coordinates\n",
    "lines_sorted = sorted(lines, key=lambda line: line[0][1])  # Sort lines based on y-coordinates\n",
    "grouped_lines = []\n",
    "current_group = [lines_sorted[0]]\n",
    "for i in range(1, len(lines_sorted)):\n",
    "    if abs(lines_sorted[i][0][1] - lines_sorted[i-1][0][1]) < 10:  # Tweak the threshold value for grouping\n",
    "        current_group.append(lines_sorted[i])\n",
    "    else:\n",
    "        grouped_lines.append(current_group)\n",
    "        current_group = [lines_sorted[i]]\n",
    "grouped_lines.append(current_group)\n",
    "\n",
    "# Draw bounding boxes on original image for each text line\n",
    "for line_group in grouped_lines:\n",
    "    min_x = min(line[0][0] for line in line_group)\n",
    "    min_y = min(line[0][1] for line in line_group)\n",
    "    max_x = max(line[0][2] for line in line_group)\n",
    "    max_y = max(line[0][3] for line in line_group)\n",
    "    cv2.rectangle(img, (min_x, min_y), (max_x, max_y), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('11.jpg', img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweak the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: (255, 245), (341, 280)\n",
      "Line 2: (310, 272), (322, 273)\n",
      "Line 3: (333, 278), (333, 252)\n",
      "Line 4: (311, 290), (1097, 361)\n",
      "Line 5: (255, 371), (498, 410)\n",
      "Line 6: (311, 424), (1142, 499)\n",
      "Line 7: (255, 519), (341, 544)\n",
      "Line 8: (255, 546), (341, 553)\n",
      "Line 9: (311, 568), (1104, 642)\n",
      "Line 10: (272, 1179), (650, 1283)\n",
      "Line 11: (307, 1291), (525, 1266)\n",
      "Line 12: (276, 1309), (532, 1345)\n",
      "Line 13: (633, 1368), (641, 1391)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg') \n",
    "\n",
    "# Create Gabor filter bank\n",
    "# Apply Gabor filter\n",
    "ksize = 31  # Size of the Gabor filter kernel (adjust based on image size and line thickness)\n",
    "sigma = 200  # Standard deviation of the Gaussian kernel (adjust based on image size and line thickness)\n",
    "theta = np.pi/4  # Orientation of the Gabor filter (horizontal)\n",
    "lambda_ = 0.1  # Wavelength of the sinusoidal factor (adjust based on line thickness)\n",
    "gamma = 0.1  # Spatial aspect ratio (adjust to get the desired response)\n",
    "gabor_kernels = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambda_, gamma)\n",
    "\n",
    "\n",
    "filtered_img = cv2.filter2D(img, cv2.CV_8UC3, gabor_kernels)\n",
    "\n",
    "# Filter image with Gabor filters\n",
    "gabor_imgs = []\n",
    "for kernel in gabor_kernels:\n",
    "    filtered_img = cv2.filter2D(img, -1, kernel)\n",
    "    gabor_imgs.append(filtered_img)\n",
    "\n",
    "# Detect edges\n",
    "edges = cv2.Canny(gabor_imgs[0], 50, 200)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, minLineLength=7, maxLineGap=8)\n",
    "\n",
    "# Group lines based on y-coordinates\n",
    "lines_sorted = sorted(lines, key=lambda line: line[0][1])  # Sort lines based on y-coordinates\n",
    "grouped_lines = []\n",
    "current_group = [lines_sorted[0]]\n",
    "for i in range(1, len(lines_sorted)):\n",
    "    if abs(lines_sorted[i][0][1] - lines_sorted[i-1][0][1]) < 4.5:  # Tweak the threshold value for grouping\n",
    "        current_group.append(lines_sorted[i])\n",
    "    else:\n",
    "        grouped_lines.append(current_group)\n",
    "        current_group = [lines_sorted[i]]\n",
    "grouped_lines.append(current_group)\n",
    "# Create a dictionary to store bounding box coordinates\n",
    "bbox_dict = {}\n",
    "\n",
    "# Draw bounding boxes on original image for each text line and save coordinates to the dictionary\n",
    "for idx, line_group in enumerate(grouped_lines, start=1):\n",
    "    min_x = min(line[0][0] for line in line_group)\n",
    "    min_y = min(line[0][1] for line in line_group)\n",
    "    max_x = max(line[0][2] for line in line_group)\n",
    "    max_y = max(line[0][3] for line in line_group)\n",
    "\n",
    "    # Convert numpy.int32 to regular Python int\n",
    "    min_x, min_y, max_x, max_y = int(min_x), int(min_y), int(max_x), int(max_y)\n",
    "\n",
    "    # Store coordinates in the dictionary\n",
    "    box_name = f\"box{idx}\"\n",
    "    bbox_dict[box_name] = {\n",
    "        \"top_left\": [min_x, min_y],\n",
    "        \"top_right\": [max_x, min_y],\n",
    "        \"bottom_left\": [min_x, max_y],\n",
    "        \"bottom_right\": [max_x, max_y]\n",
    "    }\n",
    "\n",
    "    # Draw the bounding box on the image\n",
    "    cv2.rectangle(img, (min_x, min_y), (max_x, max_y), (0, 255, 0), 2)\n",
    "\n",
    "    # Optionally, you can print the coordinates for each line\n",
    "    print(f\"Line {idx}: ({min_x}, {min_y}), ({max_x}, {max_y})\")\n",
    "\n",
    "# Save the dictionary as a JSON file\n",
    "json_file_path = 'bounding_boxes.json'\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(bbox_dict, json_file, indent=4)\n",
    "\n",
    "cv2.imwrite('11.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Saved Images using the following --- Last tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cropped image is empty for box 13. Skipping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "# Load image\n",
    "img_path = '/home/kalyan/gitrepo/NeedToStartARepo/iitb/123.png'\n",
    "img = cv2.imread(img_path) \n",
    "\n",
    "# Create Gabor filter bank\n",
    "gabor_kernels = cv2.getGaborKernel((5, 5), 4.0, theta=0, lambd=10.0, gamma=0.5)\n",
    "\n",
    "# Filter image with Gabor filters\n",
    "gabor_imgs = []\n",
    "for kernel in gabor_kernels:\n",
    "    filtered_img = cv2.filter2D(img, -1, kernel)\n",
    "    gabor_imgs.append(filtered_img)\n",
    "\n",
    "# Detect edges\n",
    "edges = cv2.Canny(gabor_imgs[0], 50, 200)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, minLineLength=10, maxLineGap=5)\n",
    "\n",
    "# Group lines based on y-coordinates\n",
    "lines_sorted = sorted(lines, key=lambda line: line[0][1])  # Sort lines based on y-coordinates\n",
    "grouped_lines = []\n",
    "current_group = [lines_sorted[0]]\n",
    "for i in range(1, len(lines_sorted)):\n",
    "    if abs(lines_sorted[i][0][1] - lines_sorted[i-1][0][1]) < 6:  # Tweak the threshold value for grouping\n",
    "        current_group.append(lines_sorted[i])\n",
    "    else:\n",
    "        grouped_lines.append(current_group)\n",
    "        current_group = [lines_sorted[i]]\n",
    "grouped_lines.append(current_group)\n",
    "\n",
    "# Create a new folder with the same name as the original image\n",
    "img_folder = os.path.splitext(os.path.basename(img_path))[0]  # Get the image file name without extension\n",
    "output_folder = os.path.join(os.path.dirname(img_path), img_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Create a dictionary to store bounding box coordinates\n",
    "bbox_dict = {}\n",
    "\n",
    "def convert_np_int_to_int(obj):\n",
    "    if isinstance(obj, np.int32):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_np_int_to_int(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_np_int_to_int(value) for key, value in obj.items()}\n",
    "    else:\n",
    "        return obj\n",
    "# Draw bounding boxes on original image for each text line and save coordinates to the dictionary\n",
    "for idx, line_group in enumerate(grouped_lines, start=1):\n",
    "    min_x = min(line[0][0] for line in line_group)\n",
    "    min_y = min(line[0][1] for line in line_group)\n",
    "    max_x = max(line[0][2] for line in line_group)\n",
    "    max_y = max(line[0][3] for line in line_group)\n",
    "    cv2.rectangle(img, (min_x, min_y), (max_x, max_y), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the cropped and boxed image in the new folder\n",
    "    cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "    if not cropped_img.any():  # Check if cropped_img is empty\n",
    "        print(f\"Warning: Cropped image is empty for box {idx}. Skipping...\")\n",
    "    else:\n",
    "        boxed_img_path = os.path.join(output_folder, f\"boxed_line_{idx}.jpg\")\n",
    "        cv2.imwrite(boxed_img_path, cropped_img)\n",
    "\n",
    "        # Store coordinates in the dictionary\n",
    "        box_name = f\"box{idx}\"\n",
    "        bbox_dict[box_name] = {\n",
    "            \"top_left\": [min_x, min_y],\n",
    "            \"top_right\": [max_x, min_y],\n",
    "            \"bottom_left\": [min_x, max_y],\n",
    "            \"bottom_right\": [max_x, max_y]\n",
    "        }\n",
    "\n",
    "# Save the dictionary as a JSON file in the same folder as the original image\n",
    "json_file_path = os.path.join(output_folder, 'bounding_boxes.json')\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(convert_np_int_to_int(bbox_dict), json_file, indent=4)\n",
    "\n",
    "\n",
    "# Save the modified image with bounding boxes\n",
    "cv2.imwrite(os.path.join(output_folder, 'Overall.jpg'), img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with Gabor and put parameters above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def gabor_filter(size, theta, frequency, sigma_x, sigma_y):\n",
    "    \"\"\"Generate a Gabor filter.\"\"\"\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))\n",
    "    x_theta = x * np.cos(theta) + y * np.sin(theta)\n",
    "    y_theta = -x * np.sin(theta) + y * np.cos(theta)\n",
    "    g = np.exp(-0.5 * (x_theta * 2 / sigma_x * 2 + y_theta * 2 / sigma_y * 2)) * np.cos(2 * np.pi * frequency * x_theta)\n",
    "    return g / np.max(g)  # Normalize the filter to have values between 0 and 1\n",
    "\n",
    "# Parameters for Gabor filter\n",
    "filter_size = 31\n",
    "theta = np.pi / 4\n",
    "frequency = 200\n",
    "sigma_x = 0.1\n",
    "sigma_y = 0.1\n",
    "\n",
    "# Create a Gabor filter\n",
    "gabor = gabor_filter(filter_size, theta, frequency, sigma_x, sigma_y)\n",
    "\n",
    "# Load your bw image here or replace 'image' with your actual image data\n",
    "image = cv2.imread('/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg') \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Apply the Gabor filter to the image using convolution\n",
    "filtered_image = convolve2d(image, gabor, mode='same', boundary='symm')\n",
    "\n",
    "# Plot the original image\n",
    "#plt.figure(figsize=(10, 10))\n",
    "#plt.imshow(image, cmap='gray', alpha=1.0)\n",
    "#\n",
    "## Plot the Gabor filter on top of the image with transparency\n",
    "#plt.imshow(gabor, cmap='gray', alpha=0.5, extent=[0, image.shape[1], image.shape[0], 0], interpolation='bilinear')\n",
    "#\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "def move_gabor_filter(gabor_filter, x, y):\n",
    "    \"\"\"Move the Gabor filter to the specified (x, y) position.\"\"\"\n",
    "    filter_size = gabor_filter.shape[0]\n",
    "    x_min, x_max = max(0, x), min(gabor_filter.shape[1], x + filter_size)\n",
    "    y_min, y_max = max(0, y), min(gabor_filter.shape[0], y + filter_size)\n",
    "    moved_filter = np.zeros_like(gabor_filter)\n",
    "    src_x_min, src_x_max = x_min - x, x_max - x\n",
    "    src_y_min, src_y_max = y_min - y, y_max - y\n",
    "    moved_filter[y_min:y_max, x_min:x_max] = gabor_filter[src_y_min:src_y_max, src_x_min:src_x_max]\n",
    "    return moved_filter\n",
    "\n",
    "# Example usage:\n",
    "# (Assuming 'gabor' is your Gabor filter generated earlier and 'x' and 'y' are the translation coordinates)\n",
    "\n",
    "x = 10  # Move the filter 10 pixels to the right\n",
    "y = 5  # Move the filter 20 pixels down\n",
    "\n",
    "moved_gabor = move_gabor_filter(gabor, x, y)\n",
    "\n",
    "# Plot moved Gabor filter\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(moved_gabor, cmap='gray', alpha=1.0)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried to increase height , without changing width -- Old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg') \n",
    "\n",
    "# Create Gabor filter bank\n",
    "gabor_kernels = cv2.getGaborKernel((5, 5), 4.0, theta=0, lambd=10.0, gamma=0.5)\n",
    "\n",
    "# Filter image with Gabor filters\n",
    "gabor_imgs = []\n",
    "for kernel in gabor_kernels:\n",
    "    filtered_img = cv2.filter2D(img, -1, kernel)\n",
    "    gabor_imgs.append(filtered_img)\n",
    "\n",
    "# Detect edges\n",
    "edges = cv2.Canny(gabor_imgs[0], 50, 200) \n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 30, minLineLength=10, maxLineGap=5)\n",
    "\n",
    "# Draw bounding boxes on original image with increased height\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    \n",
    "    # Increase the height of the bounding box by adding an offset to y-coordinates\n",
    "    y_offset = 10  # Adjust this value to control the increase in height\n",
    "    y1_new = max(0, y1 - y_offset)\n",
    "    y2_new = min(img.shape[0] - 1, y2 + y_offset)\n",
    "    \n",
    "    cv2.rectangle(img, (x1, y1_new), (x2, y2_new), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('output_with_increased_height.jpg', img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with Gabor and see it's plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img_path = '/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gabor filter\n",
    "ksize = 31  # Size of the Gabor filter kernel (adjust based on image size and line thickness)\n",
    "sigma = 5   # Standard deviation of the Gaussian kernel (adjust based on image size and line thickness)\n",
    "theta = 90  # Orientation of the Gabor filter (horizontal)\n",
    "lambda_ = 10  # Wavelength of the sinusoidal factor (adjust based on line thickness)\n",
    "gamma = 0.5  # Spatial aspect ratio (adjust to get the desired response)\n",
    "gabor_filter = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambda_, gamma)\n",
    "filtered_img = cv2.filter2D(gray_img, cv2.CV_8UC3, gabor_filter)\n",
    "\n",
    "# Find contours of horizontal lines in the filtered image\n",
    "contours, _ = cv2.findContours(filtered_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get the bounding box of the highest horizontal line\n",
    "max_y = 0\n",
    "bbox = None\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    if h > w:  # Consider only horizontal lines (adjust this condition if needed)\n",
    "        if y > max_y:\n",
    "            max_y = y\n",
    "            bbox = (x, y, w, h)\n",
    "\n",
    "#draw bounding box\n",
    "x, y, w, h = bbox\n",
    "cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the original image and the image with bounding box\n",
    "plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.title('Original Image')\n",
    "plt.plot(122), plt.imshow(cv2.cvtColor(filtered_img, cv2.COLOR_BGR2RGB)), plt.title('Image with Bounding Box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('/home/kalyan/gitrepo/NeedToStartARepo/iitb/ilovepdf_pages-to-jpg/Sanskrit_Text_page-0001.jpg')\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Perform Singular Value Decomposition (SVD)\n",
    "U, S, Vt = np.linalg.svd(gray_img)\n",
    "\n",
    "# Choose the number of singular values to use for reconstruction\n",
    "num_singular_values = 250\n",
    "\n",
    "# Reconstruct the image using selected singular values\n",
    "reconstructed_img = np.dot(U[:, :num_singular_values], np.dot(np.diag(S[:num_singular_values]), Vt[:num_singular_values, :]))\n",
    "\n",
    "# Convert the reconstructed image back to uint8 (8-bit integer)\n",
    "reconstructed_img = np.uint8(reconstructed_img)\n",
    "\n",
    "# Use OpenCV to find contours in the image\n",
    "contours, _ = cv2.findContours(reconstructed_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw bounding boxes around detected objects\n",
    "img_with_bboxes = img.copy()\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(img_with_bboxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# plot the original image and the reconstructed image\n",
    "plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)), plt.title('Original Image')\n",
    "plt.subplot(122), plt.imshow(cv2.cvtColor(reconstructed_img, cv2.COLOR_BGR2RGB)), plt.title('Reconstructed Image')\n",
    "plt.show()\n",
    "\n",
    "#save the reconstructed image\n",
    "cv2.imwrite('reconstructed_img.jpg', reconstructed_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
